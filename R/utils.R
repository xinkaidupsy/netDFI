
# ----- a fit function that does not print output -----
silent_fit <- function(model) {
  # Capture and discard printed output, return the data frame
  capture.output(
    fit_result <- fit(model),
    file = NULL
  )
  return(fit_result)
}

# ----- simulate data with seeds -----
ggm_dt_sim <- function(net, iter, n, ordinal, nLevels, skewFactor, type, missing, par_fun){

  # set up generator
  generator <- bootnet::ggmGenerator(ordinal = ordinal,
                                     nLevels = n_levels,
                                     skewFactor = skew_factor,
                                     type = type, missing = missing)

  # generate data
  dt <- par_fun(seq_len(iter), function(i) {
    data <- generator(n = 500, input = net)
  })

  return(dt)

}

# ----- net2vec -----
# obtain the lower.tri of a network, label each edge with the nodes that it connects, &
# output the vector of edges annotated with corresponding nodes
net2vec <- function(net){

  # assign row&colnames if there's none
  if (is.null(rownames(net))) {
    rownames(net) <- paste0("V", 1:nrow(net))
  }

  if (is.null(colnames(net))) {
    colnames(net) <- paste0("V", 1:ncol(net))
  }

  # obtain lower.tri
  vec <- data.frame(net[lower.tri(net)])
  names(vec) <- "weights"

  # annotate values with row&colnames
  names.Mat <- outer(rownames(net), colnames(net), paste, sep = "--")
  vec$loc <- names.Mat[lower.tri(names.Mat)]

  return(vec)

}

# ----- create misspecification -----

# add the additional parameter to the node with smallest predictability (most variance left to explain)
ggm_add <- function(net, propPos){

  # calculate predictability of each edge
  r2 <- qgraph::centrality(net, R2 = TRUE)$R2

  # calculate the summed predictability of nodes connected by each edge
  r2_sum <- matrix(r2, nrow = nrow(net), ncol = ncol(net)) +
    matrix(r2, nrow = nrow(net), ncol = ncol(net), byrow = TRUE)

  # avoid selecting diagnal and locations where there is already an edge
  r2_sum[net != 0] <- 2
  diag(r2_sum) <- 2

  # rank priorities based on summed predictability; here the weights are summed predictabilities
  # edges that connect nodes of low predictability are prioritized
  edge_df <- net2vec(r2_sum) %>%
    arrange(weights) %>%
    mutate(priority = dense_rank(weights)) %>%
    # select the top 10 (didn't involve randomization b/c doesn't seem to be necessary)
    # effect of location for edges of same summed predictability might be trivial
    head(10) %>%
    mutate(
      from = as.numeric(gsub("V(\\d+)--V\\d+", "\\1", loc)),
      to = as.numeric(gsub("V\\d+--V(\\d+)", "\\1", loc))
    )


  # # candidate r2 values
  # r2_cand <- r2_sum[lower.tri(r2_sum)] %>% unique %>% sort %>% head(10)
  #
  # which((r2_sum %in% r2_cand) & lower.tri(r2_sum))
  #
  # counter <- 1
  #
  # Reduce(`|`, lapply(r2_cand, function(x) r2_sum == x)) %>% which(arr.ind = TRUE)
  #
  # # location of smallest predictability
  # loc <- which(r2_sum == min(r2_sum), arr.ind = TRUE)
  #
  # # remove duplication
  # loc <- loc[(apply(loc, 1, sort) %>% t %>% duplicated()),]
  #
  # # in case there are multiple smallest, select one randomly
  # # set.seed(960308)
  # ind <- loc[sample(1:nrow(loc), 1),] %>% as.numeric

  # the smallest eigenvalue of the true is also negative
  # eigen(net, symmetric = TRUE, only.values = TRUE)$values %>% min

  # the weight of the new edge is the same as the edge with the smallest absolute value in the network
  # purrr::map(data, function(dt) {
  edge_vec <- net[net!=0]
  add_edge <- (edge_vec %>% abs %>% min) * sample(c(1,-1), 1, prob = c(propPos, 1-propPos))
  # sign_edge <- ifelse(cor(dt[,ind[1]], dt[,ind[2]]) > 0, 1,-1)
  # * sign_edge
  #   return(net)
  # })

  # to do:
  # determine sign based on marginal correlation in the raw data
  # might not be necessary b/c the empirical model is fit to the data generated by the misspec model, not the raw data
  # only whether the fit indices can detect that added edge matters; its sign doesn't matter
  # maybe add an option to decide the proportion of positive edges in the extra edges

  mod_misspec <- net
  counter <- 1

  while (counter <= 10) {

    # add the extra edge
    mod_misspec[edge_df$from[counter], edge_df$to[counter]] <-
      mod_misspec[edge_df$to[counter], edge_df$from[counter]] <-
      add_edge

    # check the positive definiteness of I - omega\
    eigen_vals <-  eigen((diag(nrow(mod_misspec)) - mod_misspec), symmetric = TRUE)$values

    # return the misspecified model if positive definite
    if(all(eigen_vals > 0)){
      return(mod_misspec)
    } else {
      # restore to original state
      mod_misspec <- net
      counter <- counter + 1

      # stop the function if can't find a positive definite misspec model after 10 iters
      if(counter > 10){
        stop("could not find a misspecified model that is positive definite after 10 iterations")
      }
    }
  }

}

ggm_fit_misspec <- function(net, adj_net, iter, n = n, propPos, ordinal, nLevels, skewFactor, type, missing, par_fun) {

  # create misspec model
  mod_misspec <- ggm_add(net,propPos)

  # generate data for the misspecified model
  data <- ggm_dt_sim(net = mod_misspec, iter = iter, n = n, ordinal = ordinal,
                     nLevels = nLevels, skewFactor = skewFactor,
                     type = type, missing = missing, par_fun = par_fun)

  # getting the cna that fits the empirical model to the data simulated from the misspec model
  misspec_cna <- par_fun(data, function(dt) {
    ggm(dt, omega = adj_net) %>% runmodel
  })

  # getting the fit of misspec model
  misspec_fit <- par_fun(misspec_cna, function(m) {
    silent_fit(m) %>%
      filter(Measure %in% c("cfi", "rmsea", "tli")) %>%
      mutate(Measure = NULL, Value = round(Value, 3)) %>%
      t %>% as.data.frame %>%
      `colnames<-`(c("TLI_M","CFI_M","RMSEA_M")) %>%
      mutate(Model = "misspec")
  }) %>% bind_rows %>%
    `rownames<-`(paste0("iter", 1:nrow(.))) %>% list

}

# true model --------------------------------------------------------------

ggm_fit_true <- function(net, adj_net, iter, n, ordinal, nLevels, skewFactor, type, missing, par_fun) {

  # generate data from true
  data <- ggm_dt_sim(net = net, iter = iter, n = n, ordinal = ordinal,
                     nLevels = nLevels, skewFactor = skewFactor,
                     type = type, missing = missing, par_fun = par_fun)

  # getting the true model
  true_cna <- par_fun(data, function(dt) {
    ggm(dt, omega = adj_net) %>% runmodel
  })

  # getting the true model fit
  true_fit <- par_fun(true_cna, function(m) {
    silent_fit(m) %>%
      filter(Measure %in% c("cfi", "rmsea", "tli")) %>%
      mutate(Measure = NULL, Value = round(Value, 3)) %>%
      t %>% as.data.frame %>%
      `colnames<-`(c("TLI_T","CFI_T","RMSEA_T")) %>%
      mutate(Model = "true")
  }) %>% bind_rows %>%
    `rownames<-`(paste0("iter", 1:nrow(.))) %>% list

}

fit_data <- function(true_fit, misspec_fit, par_fun){

  df_results <- par_fun(misspec_fit,function(df) {
    cbind(df,true_fit)
  })

  #Create beginning of variable name for each
  dat_name <- rep(c("TLI_L","RMSEA_L","CFI_L","Type_L"),2)

  #Create vector of 0's for the True model
  dat_0 <- rep(0,4)

  #Get number of levels of misspecification
  dat_lev <- length(df_results)

  #Create combo of Level #'s and 0's to merge with variable names (in list form)
  dat_num <- list()
  for (i in 1:dat_lev){
    output <- c(rep(i,4),dat_0)
    dat_num[[i]] <- output
  }

  #Combine variable name with level # (in list form)
  var_names <- par_fun(dat_num, function(x){
    paste0(dat_name,x)
  })

  #Rename variables in dataset list
  dat_revised <- par_fun(seq_along(df_results), function(x){
    colnames(df_results[[x]]) <- var_names[[x]]
    #not sure why I need to mention it again but I do
    df_results[[x]]
  })

  #Combine into one dataset
  df_renamed <- do.call(cbind.data.frame,dat_revised)

  #Remove the duplicate L0 info
  df_renamed2 <- df_renamed[!duplicated(colnames(df_renamed))]

  #Remove the "type" variable (unnecessary)
  df_renamed3 <- df_renamed2[, -grep("Type",colnames(df_renamed2))]

  #Reorder variables
  df_renamed4 <- df_renamed3 %>%
    dplyr::relocate(order(colnames(df_renamed3))) %>%            #gets numbers in order
    dplyr::relocate(dplyr::starts_with("TLI"),dplyr::starts_with("RMSEA"))    #gets fit indices in order

  return(df_renamed4)
}


#
#
# fit1<-unlist(Fit)%>% matrix(nrow=(length(misspec_sum)+1), ncol=6) %>%
#   `colnames<-`(c("TLI","sensitivity_tli","RMSEA","sensitivity_rmsea","CFI","sensitivity_cfi"))
#
# # ditch the cutoff if its sensitivity < 0.5
# for (j in 2:(length(misspec_sum)+1)) {
#   if(fit1[j,2]<.50){fit1[j,1]<-NA}
#   if(fit1[j,4]<.50){fit1[j,3]<-NA}
#   if(fit1[j,6]<.50){fit1[j,5]<-NA}
# }
#
# #create blanks to make table easier to read
# pp<-c(rep("--",(length(misspec_sum)+1)))
# pp0<-c(rep("",(length(misspec_sum)+1)))
#
# # #matrix of cross-loadings added at each level
# # mag <- ggm_add(net1, propPos = 0.6) %>%
# #   tidyr::separate(V1,into=c("a","b","Magnitude","d","e"),sep=" ") %>%
# #   select(Magnitude) %>%
# #   mutate(Magnitude=as.numeric(Magnitude),
# #          Magnitude=round(Magnitude,digits=3))
#
# # #Create column of cross-loadings added at each level
# # mname<-c("NONE","","")
# # for (i in 1:length(misspec_sum)){
# #   mi<-c(mag[i,],"","")
# #   mname<-cbind(mname,mi)
# # }
#
# #format column for each index and the misspecification magnitude
# TT<-noquote(matrix(rbind(fit1[,1],fit1[,2],pp0),ncol=1))
# RR<-noquote(matrix(rbind(fit1[,3],fit1[,4],pp0),ncol=1))
# CC<-noquote(matrix(rbind(fit1[,5],fit1[,6],pp0),ncol=1))
# # MM<-noquote(matrix(mname, ncol=1))
#
# # #bind columns together into one table
# # Table<-noquote(cbind(TT,RR,CC,MM) %>%
# #                  `colnames<-`(c("TLI","RMSEA","CFI","Magnitude")))
#
# #bind columns together into one table
# Table<-noquote(cbind(TT,RR,CC) %>%
#                  `colnames<-`(c("TLI","RMSEA","CFI")))
#
# #update row names
# rname<-c("Level-0","Specificity", "")
# for (i in 1:length(misspec_sum)){
#   ri<-c(paste("Level-",i,sep=""),"Sensitivity","")
#   rname<-cbind(rname,ri)
# }
# rownames(Table)<-rname
#
# #delete last blank row
# Table<-Table[1:(nrow(Table)-1),]
#
# #Put into list
# res$cutoffs <- Table

